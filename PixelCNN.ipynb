{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "n_residual_blocks = 5\n",
    "# The data, split between train and test sets\n",
    "(x, _), (y, _) = keras.datasets.mnist.load_data()\n",
    "# Concatenate all of the images together\n",
    "data = np.concatenate((x, y), axis=0)\n",
    "# Round all pixel values less than 33% of the max 256 value to 0\n",
    "# anything above this value gets rounded up to 1 so that all values are either\n",
    "# 0 or 1\n",
    "data = np.where(data < (0.33 * 256), 0, 1)\n",
    "data = data.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create two classes for the requisite Layers for the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first layer is the PixelCNN layer. This layer simply\n",
    "# builds on the 2D convolutional layer, but includes masking.\n",
    "class PixelConvLayer(layers.Layer):\n",
    "    def __init__(self, mask_type, **kwargs):\n",
    "        super(PixelConvLayer, self).__init__()\n",
    "        self.mask_type = mask_type\n",
    "        self.conv = layers.Conv2D(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Build the conv2d layer to initialize kernel variables\n",
    "        self.conv.build(input_shape)\n",
    "        # Use the initialized kernel to create the mask\n",
    "        kernel_shape = self.conv.kernel.get_shape()\n",
    "        self.mask = np.zeros(shape=kernel_shape)\n",
    "        self.mask[: kernel_shape[0] // 2, ...] = 1.0\n",
    "        self.mask[kernel_shape[0] // 2, : kernel_shape[1] // 2, ...] = 1.0\n",
    "        if self.mask_type == \"B\":\n",
    "            self.mask[kernel_shape[0] // 2, kernel_shape[1] // 2, ...] = 1.0\n",
    "\n",
    "    def call(self, inputs):\n",
    "        self.conv.kernel.assign(self.conv.kernel * self.mask)\n",
    "        return self.conv(inputs)\n",
    "\n",
    "\n",
    "# Next, we build our residual block layer.\n",
    "# This is just a normal residual block, but based on the PixelConvLayer.\n",
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, filters, **kwargs):\n",
    "        super(ResidualBlock, self).__init__(**kwargs)\n",
    "        self.conv1 = keras.layers.Conv2D(\n",
    "            filters=filters, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "        self.pixel_conv = PixelConvLayer(\n",
    "            mask_type=\"B\",\n",
    "            filters=filters // 2,\n",
    "            kernel_size=3,\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        )\n",
    "        self.conv2 = keras.layers.Conv2D(\n",
    "            filters=filters, kernel_size=1, activation=\"relu\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pixel_conv(x)\n",
    "        x = self.conv2(x)\n",
    "        return keras.layers.add([inputs, x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the model based on the original paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer (PixelConvL (None, 28, 28, 128)       6400      \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_4 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_6 (PixelCon (None, 28, 28, 128)       16512     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_7 (PixelCon (None, 28, 28, 128)       16512     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 1)         129       \n",
      "=================================================================\n",
      "Total params: 532,673\n",
      "Trainable params: 532,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "438/438 [==============================] - 1353s 3s/step - loss: 0.1180 - val_loss: 0.0930\n",
      "Epoch 2/50\n",
      "438/438 [==============================] - 1313s 3s/step - loss: 0.0913 - val_loss: 0.0915\n",
      "Epoch 3/50\n",
      "438/438 [==============================] - 1280s 3s/step - loss: 0.0893 - val_loss: 0.0888\n",
      "Epoch 4/50\n",
      "438/438 [==============================] - 1273s 3s/step - loss: 0.0881 - val_loss: 0.0879\n",
      "Epoch 5/50\n",
      "438/438 [==============================] - 1335s 3s/step - loss: 0.0873 - val_loss: 0.0870\n",
      "Epoch 6/50\n",
      "438/438 [==============================] - 1349s 3s/step - loss: 0.0867 - val_loss: 0.0864\n",
      "Epoch 7/50\n",
      "438/438 [==============================] - 1285s 3s/step - loss: 0.0862 - val_loss: 0.0861\n",
      "Epoch 8/50\n",
      "438/438 [==============================] - 1362s 3s/step - loss: 0.0858 - val_loss: 0.0859\n",
      "Epoch 9/50\n",
      "438/438 [==============================] - 1450s 3s/step - loss: 0.0855 - val_loss: 0.0855\n",
      "Epoch 10/50\n",
      "438/438 [==============================] - 1830s 4s/step - loss: 0.0852 - val_loss: 0.0854\n",
      "Epoch 11/50\n",
      " 16/438 [>.............................] - ETA: 29:54 - loss: 0.0842"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=input_shape)\n",
    "x = PixelConvLayer(\n",
    "    mask_type=\"A\", filters=128, kernel_size=7, activation=\"relu\", padding=\"same\"\n",
    ")(inputs)\n",
    "\n",
    "for _ in range(n_residual_blocks):\n",
    "    x = ResidualBlock(filters=128)(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    x = PixelConvLayer(\n",
    "        mask_type=\"B\",\n",
    "        filters=128,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        activation=\"relu\",\n",
    "        padding=\"valid\",\n",
    "    )(x)\n",
    "\n",
    "out = keras.layers.Conv2D(\n",
    "    filters=1, kernel_size=1, strides=1, activation=\"sigmoid\", padding=\"valid\"\n",
    ")(x)\n",
    "\n",
    "pixel_cnn = keras.Model(inputs, out)\n",
    "adam = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "pixel_cnn.compile(optimizer=adam, loss=\"binary_crossentropy\")\n",
    "\n",
    "pixel_cnn.summary()\n",
    "pixel_cnn.fit(\n",
    "    x=data, y=data, batch_size=128, epochs=50, validation_split=0.2, verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pixel_cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a0b82b2c94e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpixel_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_model/5PixelCNN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pixel_cnn' is not defined"
     ]
    }
   ],
   "source": [
    "pixel_cnn.save('saved_model/PixelCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer (PixelConvL (None, 28, 28, 128)       6400      \n",
      "_________________________________________________________________\n",
      "residual_block (ResidualBloc (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_1 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_2 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_3 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "residual_block_4 (ResidualBl (None, 28, 28, 128)       98624     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_6 (PixelCon (None, 28, 28, 128)       16512     \n",
      "_________________________________________________________________\n",
      "pixel_conv_layer_7 (PixelCon (None, 28, 28, 128)       16512     \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 28, 28, 1)         129       \n",
      "=================================================================\n",
      "Total params: 532,673\n",
      "Trainable params: 532,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pixel_cnn = tf.keras.models.load_model('saved_model/PixelCNN')\n",
    "pixel_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████████████████████████████████▋                          | 19/28 [00:36<00:16,  1.85s/it]"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "# Create an empty array of pixels.\n",
    "batch = 4\n",
    "pixels = np.zeros(shape=(batch,) + (pixel_cnn.input_shape)[1:])\n",
    "batch, rows, cols, channels = pixels.shape\n",
    "\n",
    "# Iterate over the pixels because generation has to be done sequentially pixel by pixel.\n",
    "for row in tqdm(range(rows)):\n",
    "    for col in range(cols):\n",
    "        for channel in range(channels):\n",
    "            # Feed the whole array and retrieving the pixel value probabilities for the next\n",
    "            # pixel.\n",
    "            probs = pixel_cnn.predict(pixels)[:, row, col, channel]\n",
    "            # Use the probabilities to pick pixel values and append the values to the image\n",
    "            # frame.\n",
    "            pixels[:, row, col, channel] = tf.math.ceil(\n",
    "                probs - tf.random.uniform(probs.shape)\n",
    "            )\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # Stack the single channeled black and white image to RGB values.\n",
    "    x = np.stack((x, x, x), 2)\n",
    "    # Undo preprocessing\n",
    "    x *= 255.0\n",
    "    # Convert to uint8 and clip to the valid range [0, 255]\n",
    "    x = np.clip(x, 0, 255).astype(\"uint8\")\n",
    "    return x\n",
    "\n",
    "# Iterate over the generated images and plot them with matplotlib.\n",
    "for i, pic in enumerate(pixels):\n",
    "    keras.preprocessing.image.save_img(\n",
    "        \"generated_image_{}.png\".format(i), deprocess_image(np.squeeze(pic, -1))\n",
    "    )\n",
    "\n",
    "display(Image(\"generated_image_0.png\"))\n",
    "display(Image(\"generated_image_1.png\"))\n",
    "display(Image(\"generated_image_2.png\"))\n",
    "display(Image(\"generated_image_3.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
